{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec743ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps_and_Programs\\anaconda\\envs\\CNN_TF_GPU\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">169</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,880</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m1\u001b[0m)      â”‚            \u001b[38;5;34m10\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m169\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m10,880\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚           \u001b[38;5;34m330\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,300</span> (51.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,300\u001b[0m (51.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,300</span> (51.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,300\u001b[0m (51.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(1,(3, 3),strides=(1,1), activation='relu', padding='valid',input_shape=(28,28,1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.save(\"model1.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa43041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Loading model...\n",
      "âš™ï¸ Running dummy inference to collect shapes...\n",
      "âš™ï¸ Running dummy inference with shape: [1, 28, 28, 1]\n",
      "\n",
      "âœ… Hardware model saved to hardware_model.json\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "MODEL_PATH = \"model1.keras\"\n",
    "OUT_PATH = \"hardware_model.json\"\n",
    "\n",
    "SUPPORTED_LAYERS = {\n",
    "    \"Conv2D\": {\n",
    "        \"supported\": [\"filters\", \"kernel_size\", \"strides\", \"activation\"],\n",
    "        \"valid_activations\": [\"relu\", None],\n",
    "    },\n",
    "    \"MaxPooling2D\": {\"supported\": [\"pool_size\", \"strides\"]},\n",
    "    \"Dense\": {\n",
    "        \"supported\": [\"units\", \"activation\"],\n",
    "        \"valid_activations\": [\"relu\", \"sigmoid\", \"softmax\"],\n",
    "    },\n",
    "    \"Flatten\": {\"supported\": []},\n",
    "}\n",
    "\n",
    "def get_tensor_shape(tensor):\n",
    "    if tensor is None:\n",
    "        return None\n",
    "    return [int(s) if s is not None else None for s in tensor.shape]\n",
    "\n",
    "def infer_layer_shapes(model):\n",
    "    \"\"\"Run a dummy forward pass through each layer to infer in/out shapes.\"\"\"\n",
    "    # Dynamically detect input shape\n",
    "    if hasattr(model, \"inputs\") and model.inputs:\n",
    "        shape = model.inputs[0].shape\n",
    "    elif hasattr(model, \"input_shape\") and model.input_shape:\n",
    "        shape = model.input_shape\n",
    "    else:\n",
    "        raise ValueError(\"âŒ Could not detect input shape for model.\")\n",
    "\n",
    "    # Replace None (batch dim) with 1\n",
    "    shape = [1 if s is None else s for s in shape]\n",
    "    dummy_input = tf.zeros(shape)\n",
    "\n",
    "    print(f\"âš™ï¸ Running dummy inference with shape: {shape}\")\n",
    "    layer_shapes = []\n",
    "    x = dummy_input\n",
    "    for layer in model.layers:\n",
    "        in_shape = get_tensor_shape(x)\n",
    "        x = layer(x)\n",
    "        out_shape = get_tensor_shape(x)\n",
    "        layer_shapes.append((in_shape, out_shape))\n",
    "    return layer_shapes\n",
    "\n",
    "def scalarize(param):\n",
    "    \"\"\"Convert tuple/list params (like (3,3)) into single scalar (e.g., 3).\"\"\"\n",
    "    if isinstance(param, (list, tuple)):\n",
    "        if len(set(param)) == 1:\n",
    "            return param[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Hardware only supports square params, got {param}\")\n",
    "    return param\n",
    "\n",
    "def extract_layer_info(layer, in_shape, out_shape):\n",
    "    \"\"\"Extract simplified hardware-friendly parameters.\"\"\"\n",
    "    ltype = layer.__class__.__name__\n",
    "    cfg = layer.get_config()\n",
    "    layer_data = {\"name\": layer.name, \"type\": ltype}\n",
    "\n",
    "    # --- Input shape parsing ---\n",
    "    if in_shape and len(in_shape) == 4:\n",
    "        _, in_h, in_w, in_c = in_shape\n",
    "        layer_data[\"input_shape\"] = [in_h, in_w]\n",
    "        layer_data[\"input_channels\"] = in_c\n",
    "    elif in_shape and len(in_shape) == 2:\n",
    "        _, n = in_shape\n",
    "        layer_data[\"input_shape\"] = [n]\n",
    "        layer_data[\"input_channels\"] = 1\n",
    "\n",
    "    # --- Output shape parsing ---\n",
    "    if out_shape and len(out_shape) == 4:\n",
    "        _, out_h, out_w, out_c = out_shape\n",
    "        layer_data[\"output_shape\"] = [out_h, out_w]\n",
    "        layer_data[\"output_channels\"] = out_c\n",
    "    elif out_shape and len(out_shape) == 2:\n",
    "        _, n = out_shape\n",
    "        layer_data[\"output_shape\"] = [n]\n",
    "        layer_data[\"output_channels\"] = n\n",
    "\n",
    "    # --- Supported params ---\n",
    "    for key in SUPPORTED_LAYERS.get(ltype, {}).get(\"supported\", []):\n",
    "        if key in cfg:\n",
    "            val = cfg[key]\n",
    "            keyname = \"stride\" if key == \"strides\" else key\n",
    "            layer_data[keyname] = scalarize(val)\n",
    "\n",
    "    # --- Activation ---\n",
    "    act = cfg.get(\"activation\", None)\n",
    "    if act and act not in SUPPORTED_LAYERS.get(ltype, {}).get(\"valid_activations\", [act]):\n",
    "        raise ValueError(f\"Unsupported activation {act} in layer {layer.name}\")\n",
    "    if act:\n",
    "        layer_data[\"activation\"] = act\n",
    "\n",
    "    return layer_data\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸ” Loading model...\")\n",
    "    model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "    print(\"âš™ï¸ Running dummy inference to collect shapes...\")\n",
    "    layer_shapes = infer_layer_shapes(model)\n",
    "\n",
    "    layers_out = []\n",
    "    for layer, (in_shape, out_shape) in zip(model.layers, layer_shapes):\n",
    "        layers_out.append(extract_layer_info(layer, in_shape, out_shape))\n",
    "\n",
    "    model_info = {\"model_name\": model.name, \"layers\": layers_out}\n",
    "    with open(OUT_PATH, \"w\") as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… Hardware model saved to {OUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed52006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hardware model written to hardware_model.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# --------------------------- Configuration --------------------------- #\n",
    "\n",
    "INPUT_FILE = \"software_model.json\"   # output of Stage 1\n",
    "OUTPUT_FILE = \"hardware_model.json\"  # final output JSON for Stage 2\n",
    "\n",
    "GLOBAL_DEFAULTS = {\n",
    "    \"DATA_WIDTH\": 16,\n",
    "    \"FRACTION_SIZE\": 14,\n",
    "    \"SIGNED\": 1,\n",
    "    \"GUARD_TYPE\": 2\n",
    "}\n",
    "\n",
    "# --------------------------- Block Builders --------------------------- #\n",
    "\n",
    "def make_imgbuf_block(name, layer, idx, prev_out):\n",
    "    \"\"\"Creates ImageBufferChnl block JSON.\"\"\"\n",
    "    k = layer.get(\"kernel_size\", layer.get(\"pool_size\"))\n",
    "    return {\n",
    "        name: {\n",
    "            \"module\": \"ImageBufferChnl\",\n",
    "            \"parameters\": {\n",
    "                \"KERNEL_SIZE\": k,\n",
    "                \"DATA_WIDTH\": \"DATA_WIDTH\",\n",
    "                \"COLUMN_NUM\": layer[\"input_shape\"][0],\n",
    "                \"ROW_NUM\": layer[\"input_shape\"][1],\n",
    "                \"STRIDE\": layer[\"stride\"],\n",
    "                \"CHANNELS\": layer[\"input_channels\"]\n",
    "            },\n",
    "            \"inputs\": {\n",
    "                \"clock\": {\"name\": \"clock\", \"width\": 1},\n",
    "                \"sreset_n\": {\"name\": \"sreset_n\", \"width\": 1},\n",
    "                \"data_valid\": {\"name\": \"data_valid\" if idx == 1 else f\"{prev_out}_valid\", \"width\": 1},\n",
    "                \"data_in\": {\"name\": \"data_in\" if idx == 1 else prev_out, \"width\": \"DATA_WIDTH\"}\n",
    "            },\n",
    "            \"outputs\": {\n",
    "                \"data_out\": {\"name\": f\"{name}_out\", \"width\": \"DATA_WIDTH\"},\n",
    "                \"kernel_out\": {\"name\": f\"kernel_out_{name}\", \"width\": f\"DATA_WIDTH * {k} * {k}\"},\n",
    "                \"kernel_valid\": {\"name\": f\"kernel_valid_{name}\", \"width\": 1}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def make_conv_block(name, layer, ibuf_name, idx):\n",
    "    \"\"\"Creates ConvChnl block JSON (now points to .mif files).\"\"\"\n",
    "    k = layer[\"kernel_size\"]\n",
    "    return {\n",
    "        name: {\n",
    "            \"module\": \"ConvChnl\",\n",
    "            \"parameters\": {\n",
    "                \"KERNEL_SIZE\": k,\n",
    "                \"CHANNELS\": layer[\"input_channels\"],\n",
    "                \"DATA_WIDTH\": \"DATA_WIDTH\",\n",
    "                \"FRACTION_SIZE\": \"FRACTION_SIZE\",\n",
    "                \"SIGNED\": \"SIGNED\",\n",
    "                \"ACTIVATION\": layer.get(\"activation\", \"none\"),\n",
    "                \"GUARD_TYPE\": \"GUARD_TYPE\"\n",
    "            },\n",
    "            \"files\": {\n",
    "                \"weights_file\": f\"conv_L{idx}_weights.mif\",\n",
    "                \"biases_file\": f\"conv_L{idx}_biases.mif\"\n",
    "            },\n",
    "            \"inputs\": {\n",
    "                \"clock\": {\"name\": \"clock\", \"width\": 1},\n",
    "                \"sreset_n\": {\"name\": \"sreset_n\", \"width\": 1},\n",
    "                \"data_valid\": {\"name\": f\"kernel_valid_{ibuf_name}\", \"width\": 1},\n",
    "                \"kernel_in\": {\"name\": f\"kernel_out_{ibuf_name}\", \"width\": f\"DATA_WIDTH * {k} * {k}\"}\n",
    "            },\n",
    "            \"outputs\": {\n",
    "                \"conv_out\": {\"name\": f\"{name}_out\", \"width\": \"DATA_WIDTH\"},\n",
    "                \"conv_valid\": {\"name\": f\"{name}_valid\", \"width\": 1}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def make_maxpool_block(name, layer, ibuf_name):\n",
    "    \"\"\"Creates MaxpoolChnl block JSON.\"\"\"\n",
    "    k = layer[\"pool_size\"]\n",
    "    return {\n",
    "        name: {\n",
    "            \"module\": \"MaxpoolChnl\",\n",
    "            \"parameters\": {\n",
    "                \"KERNEL_SIZE\": k,\n",
    "                \"DATA_WIDTH\": \"DATA_WIDTH\",\n",
    "                \"SIGNED\": \"SIGNED\",\n",
    "                \"CHANNELS\": layer[\"input_channels\"]\n",
    "            },\n",
    "            \"inputs\": {\n",
    "                \"clock\": {\"name\": \"clock\", \"width\": 1},\n",
    "                \"sreset_n\": {\"name\": \"sreset_n\", \"width\": 1},\n",
    "                \"data_valid\": {\"name\": f\"kernel_valid_{ibuf_name}\", \"width\": 1},\n",
    "                \"kernel_in\": {\"name\": f\"kernel_out_{ibuf_name}\", \"width\": f\"DATA_WIDTH * {k} * {k}\"}\n",
    "            },\n",
    "            \"outputs\": {\n",
    "                \"maxp_out\": {\"name\": f\"{name}_out\", \"width\": \"DATA_WIDTH\"},\n",
    "                \"maxp_valid\": {\"name\": f\"{name}_valid\", \"width\": 1}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def build_nn_block(prev_out_signal, dense_layers):\n",
    "    \"\"\"Creates the NN structure (Dense layers referencing .mif files).\"\"\"\n",
    "    nn_layers = []\n",
    "    for i, layer in enumerate(dense_layers, start=1):\n",
    "        entry = {\n",
    "            \"name\": f\"dense_L{i}\",\n",
    "            \"num_inputs\": layer.get(\"input_shape\", [\"TO_BE_FILLED\"])[0],\n",
    "            \"num_neurons\": layer[\"units\"],\n",
    "            \"activation\": layer.get(\"activation\", \"TO_BE_FILLED\"),\n",
    "            \"weights_file\": f\"weights_L{i}.mif\",\n",
    "            \"biases_file\": f\"biases_L{i}.mif\"\n",
    "        }\n",
    "        nn_layers.append(entry)\n",
    "\n",
    "    return {\n",
    "        \"Build\": True,\n",
    "        \"globals\": {\n",
    "            \"DATA_WIDTH\": \"DATA_WIDTH\",\n",
    "            \"FRACTION_SIZE\": \"FRACTION_SIZE\",\n",
    "            \"SIGNED\": \"SIGNED\"\n",
    "        },\n",
    "        \"io\": {\n",
    "            \"input_signal\": prev_out_signal,\n",
    "            \"input_valid\": f\"{prev_out_signal}_valid\",\n",
    "            \"output_signal\": \"nn_out\",\n",
    "            \"output_valid\": \"nn_valid\"\n",
    "        },\n",
    "        \"layers\": nn_layers\n",
    "    }\n",
    "\n",
    "def make_maxfinder_block(prev_out_signal, num_outputs):\n",
    "    \"\"\"Creates a fixed MaxFinder block as the final stage.\"\"\"\n",
    "    return {\n",
    "        \"maxFinder\": {\n",
    "            \"module\": \"maxFinder\",\n",
    "            \"parameters\": {\n",
    "                \"NUM_INPUTS\": num_outputs,\n",
    "                \"DATA_WIDTH\": \"DATA_WIDTH\",\n",
    "                \"SIGNED\": \"SIGNED\"\n",
    "            },\n",
    "            \"inputs\": {\n",
    "                \"clock\": {\"name\": \"clock\", \"width\": 1},\n",
    "                \"sreset_n\": {\"name\": \"sreset_n\", \"width\": 1},\n",
    "                \"data_valid\": {\"name\": f\"{prev_out_signal}_valid\", \"width\": 1},\n",
    "                \"data_in\": {\"name\": prev_out_signal, \"width\": f\"DATA_WIDTH * {num_outputs}\"}\n",
    "            },\n",
    "            \"outputs\": {\n",
    "                \"class_idx\": {\"name\": \"class_idx\", \"width\": \"log2(NUM_INPUTS)\"},\n",
    "                \"valid\": {\"name\": \"class_valid\", \"width\": 1}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# --------------------------- Main Conversion --------------------------- #\n",
    "\n",
    "def main():\n",
    "    with open(INPUT_FILE, \"r\") as f:\n",
    "        model = json.load(f)\n",
    "\n",
    "    layers = model[\"layers\"]\n",
    "    globals_ = GLOBAL_DEFAULTS.copy()\n",
    "\n",
    "    top = {\n",
    "        \"module\": \"CNN\",\n",
    "        \"hardware parameters\": globals_,\n",
    "        \"inputs\": {\n",
    "            \"clock\": 1,\n",
    "            \"sreset_n\": 1,\n",
    "            \"data_in\": \"DATA_WIDTH\",\n",
    "            \"data_valid\": 1\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"class_idx\": \"log2(NUM_INPUTS)\",\n",
    "            \"class_valid\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    prev_out = \"data_in\"\n",
    "    stage_idx = 1\n",
    "    dense_layers = []\n",
    "\n",
    "    for layer in layers:\n",
    "        ltype = layer[\"type\"]\n",
    "\n",
    "        if ltype == \"Conv2D\":\n",
    "            ibuf_name = f\"ImageBuffer_Conv{stage_idx}\"\n",
    "            conv_name = f\"Conv{stage_idx}\"\n",
    "            top.update(make_imgbuf_block(ibuf_name, layer, stage_idx, prev_out))\n",
    "            top.update(make_conv_block(conv_name, layer, ibuf_name, stage_idx))\n",
    "            prev_out = f\"{conv_name}_out\"\n",
    "            stage_idx += 1\n",
    "\n",
    "        elif ltype == \"MaxPooling2D\":\n",
    "            ibuf_name = f\"ImageBuffer_Maxpool{stage_idx}\"\n",
    "            pool_name = f\"Maxpool{stage_idx}\"\n",
    "            top.update(make_imgbuf_block(ibuf_name, layer, stage_idx, prev_out))\n",
    "            top.update(make_maxpool_block(pool_name, layer, ibuf_name))\n",
    "            prev_out = f\"{pool_name}_out\"\n",
    "            stage_idx += 1\n",
    "\n",
    "        elif ltype == \"Flatten\":\n",
    "            continue  # Flatten handled implicitly\n",
    "\n",
    "        elif ltype == \"Dense\":\n",
    "            dense_layers.append(layer)\n",
    "\n",
    "    # Add NN + MaxFinder\n",
    "    if dense_layers:\n",
    "        top[\"NN\"] = build_nn_block(prev_out, dense_layers)\n",
    "        last_layer = dense_layers[-1]\n",
    "        num_outputs = last_layer[\"units\"]\n",
    "        top.update(make_maxfinder_block(\"nn_out\", num_outputs))\n",
    "    else:\n",
    "        # No NN present, direct connection to output\n",
    "        top[\"outputs\"] = {\n",
    "            \"data_out\": prev_out,\n",
    "            \"data_valid\": f\"{prev_out}_valid\"\n",
    "        }\n",
    "\n",
    "    final_json = {\"Hardware_model\": {\"top\": top}}\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\") as f:\n",
    "        json.dump(final_json, f, indent=2)\n",
    "\n",
    "    print(f\"âœ… Hardware model written to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN_TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
